import os
import json
import argparse
from typing import List, Optional

from dotenv import load_dotenv

# RAGAS / evaluation
import pandas as pd
from datasets import Dataset as HFDataset
from ragas import evaluate
# ‡πÉ‡∏ä‡πâ metric ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£: answer_relevancy + metrics ‡∏´‡∏•‡∏±‡∏Å‡∏≠‡∏∑‡πà‡∏ô‡πÜ
from ragas.metrics import (
    answer_relevancy,
    faithfulness,
    context_precision,
    context_recall,
)

# RAG system
from app.birth_date_parser import generate_birth_chart_prediction


def load_generated_dataset(path: str, limit: Optional[int] = None) -> List[dict]:
    """Load questions/ground truths/contexts from generated_dataset.json.

    Args:
        path: path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå JSON
        limit: ‡∏ñ‡πâ‡∏≤‡∏Å‡∏≥‡∏´‡∏ô‡∏î ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÅ‡∏Ñ‡πà N ‡∏Ç‡πâ‡∏≠‡πÅ‡∏£‡∏Å (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ó‡∏™ / ‡πÄ‡∏ó‡∏£‡∏ô)
    """
    with open(path, "r", encoding="utf-8") as f:
        data = json.load(f)
    if not isinstance(data, list):
        raise ValueError("generated_dataset.json ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô list ‡∏Ç‡∏≠‡∏á objects")
    if limit is not None and limit > 0:
        data = data[:limit]
    return data


def run_rag_inference(dataset: List[dict]) -> pd.DataFrame:
    """Run RAG for each question without follow-up / history.

    - ‡πÉ‡∏ä‡πâ user_id ‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° (eval_0, eval_1, ...)
      ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á (no follow-up, no shared history)
    - ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• context ‡∏à‡∏≤‡∏Å dataset ‡∏ï‡∏≠‡∏ô‡∏ñ‡∏≤‡∏° RAG (‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÉ‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô Ragas)
    """
    questions: List[str] = []
    answers: List[str] = []
    ground_truths: List[str] = []
    contexts: List[List[str]] = []  # RAGAS ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô list ‡∏Ç‡∏≠‡∏á list[str]

    for idx, item in enumerate(dataset):
        question = item.get("question", "").strip()
        gt = item.get("ground_truth") or item.get("answer") or ""
        ctx = item.get("context", "")

        if not question:
            continue

        user_id = f"eval_{idx}"  # user ‡πÉ‡∏´‡∏°‡πà‡∏ï‡πà‡∏≠‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° -> ‡πÑ‡∏°‡πà‡∏°‡∏µ follow-up history

        print("\n" + "=" * 80)
        print(f"[RAG EVAL] #{idx} question: {question}")
        print("=" * 80)

        try:
            # ‡πÉ‡∏ä‡πâ‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏£‡∏¥‡∏á: generate_birth_chart_prediction
            # ‡∏ã‡∏∂‡πà‡∏á‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏à‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏Å ask_question_to_rag ‡∏û‡∏£‡πâ‡∏≠‡∏° chart_info ‡πÅ‡∏•‡∏∞ logic ‡πÄ‡∏ï‡πá‡∏°
            rag_answer = generate_birth_chart_prediction(message=question, user_id=user_id)
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏Å generate_birth_chart_prediction: {e}")
            rag_answer = ""

        questions.append(question)
        answers.append(rag_answer or "")
        ground_truths.append(gt or "")
        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö RAGAS ‡πÉ‡∏´‡πâ context ‡πÄ‡∏õ‡πá‡∏ô list ‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (‡∏à‡∏≤‡∏Å dataset)
        contexts.append([ctx] if isinstance(ctx, str) else [str(ctx)])

    df = pd.DataFrame(
        {
            "question": questions,
            "answer": answers,
            "ground_truth": ground_truths,
            "contexts": contexts,
        }
    )
    return df


def evaluate_with_ragas_main():
    """Main entrypoint for running RAGAS evaluation.

    ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å generated_dataset.json ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö RAG
    ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ follow-up ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ chat history ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
    """
    load_dotenv()

    parser = argparse.ArgumentParser(
        description="Evaluate RAG answers with RAGAS using generated_dataset.json"
    )
    parser.add_argument(
        "--limit",
        "-n",
        type=int,
        default=None,
        help="‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô (‡πÄ‡∏ä‡πà‡∏ô 50). ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏ó‡∏∏‡∏Å‡∏Ç‡πâ‡∏≠‡πÉ‡∏ô generated_dataset.json",
    )
    args = parser.parse_args()

    dataset_path = os.path.join(os.path.dirname(__file__), "generated_dataset.json")
    if not os.path.exists(dataset_path):
        raise FileNotFoundError(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå generated_dataset.json ‡∏ó‡∏µ‡πà {dataset_path}")

    print(f"üìÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î dataset ‡∏à‡∏≤‡∏Å {dataset_path}...")
    dataset = load_generated_dataset(dataset_path, limit=args.limit)
    print(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(dataset)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£"
          f"{' (‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏î‡πâ‡∏ß‡∏¢ --limit)' if args.limit else ''}")

    # ‡∏£‡∏±‡∏ô‡∏£‡∏∞‡∏ö‡∏ö RAG ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÉ‡∏´‡∏°‡πà
    print("\nüöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏±‡∏ô RAG ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô RAGAS...")
    df = run_rag_inference(dataset)

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á HuggingFace Dataset ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Ragas
    hf_dataset = HFDataset.from_pandas(df)

    print("\nüìä ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏î‡πâ‡∏ß‡∏¢ RAGAS ...")
    result = evaluate(
        hf_dataset,
        metrics=[
            answer_relevancy,
            faithfulness,
            context_precision,
            context_recall,
        ],
    )

    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    out_csv = os.path.join(os.path.dirname(__file__), "ragas_evaluation_results.csv")
    out_json = os.path.join(os.path.dirname(__file__), "ragas_summary.json")

    print(f"\nüíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏£‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠‡πÑ‡∏õ‡∏ó‡∏µ‡πà {out_csv}")
    result_df = result.to_pandas()
    result_df.to_csv(out_csv, index=False)

    print(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏£‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠‡πÑ‡∏õ‡∏ó‡∏µ‡πà {out_json}")
    # summary ‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏≤‡∏Å ragas (‡∏≠‡∏≤‡∏à‡∏°‡∏µ NaN ‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì)
    summary = {metric: float(score) for metric, score in result.items()}

    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö JSON: summary + per-example results (‡πÑ‡∏°‡πà‡∏î‡∏±‡∏î‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)
    metric_cols = [c for c in result_df.columns if c not in ("question", "answer", "ground_truth", "contexts")]
    detailed_results = []
    for idx, row in result_df.iterrows():
        # ‡∏ó‡∏≥ contexts ‡πÉ‡∏´‡πâ serialize ‡πÑ‡∏î‡πâ‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô (list[str])
        raw_ctx = row.get("contexts", [])
        if isinstance(raw_ctx, (list, tuple)):
            ctx_serializable = [str(x) for x in raw_ctx]
        else:
            # pandas / ragas ‡∏ö‡∏≤‡∏á‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏≠‡∏≤‡∏à‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô ndarray ‡∏´‡∏£‡∏∑‡∏≠ object ‡∏≠‡∏∑‡πà‡∏ô
            try:
                ctx_list = raw_ctx.tolist()  # type: ignore[attr-defined]
                if isinstance(ctx_list, (list, tuple)):
                    ctx_serializable = [str(x) for x in ctx_list]
                else:
                    ctx_serializable = [str(ctx_list)]
            except Exception:
                ctx_serializable = [str(raw_ctx)] if raw_ctx not in (None, "") else []

        detailed_results.append(
            {
                "index": int(idx),
                "question": row.get("question", ""),
                "ground_truth": row.get("ground_truth", ""),
                "answer": row.get("answer", ""),
                "contexts": ctx_serializable,
                "metrics": {
                    m: float(row[m]) if m in row and pd.notna(row[m]) else None
                    for m in metric_cols
                },
            }
        )

    summary_payload = {
        "summary": summary,
        "results": detailed_results,
    }

    with open(out_json, "w", encoding="utf-8") as f:
        json.dump(summary_payload, f, ensure_ascii=False, indent=2)

    print("\n‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô RAGAS")
    print("‡∏ú‡∏•‡∏™‡∏£‡∏∏‡∏õ (‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢):")
    for metric, score in summary.items():
        print(f"- {metric}: {score:.4f}")

    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏£‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠‡πÅ‡∏ö‡∏ö‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡πÉ‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡∏°‡∏¥‡∏ô‡∏±‡∏•‡∏î‡πâ‡∏ß‡∏¢ (‡∏à‡∏≤‡∏Å result_df)
    print("\nüìã ‡∏ú‡∏•‡∏£‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠ (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á):")
    cols = [c for c in result_df.columns if c not in ("question", "answer", "ground_truth", "contexts")]
    for idx, row in result_df.iterrows():
        q = str(row.get("question", ""))[:60].replace("\n", " ")
        metrics_str = ", ".join(f"{m}={row[m]:.4f}" for m in cols if m in row and pd.notna(row[m]))
        print(f"[{idx}] {q} ... | {metrics_str}")


if __name__ == "__main__":
    evaluate_with_ragas_main()
