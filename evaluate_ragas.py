"""
Ragas Evaluation Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ä‡∏ó‡∏ö‡∏≠‡∏ó‡πÇ‡∏´‡∏£‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå

‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ Ragas framework ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö RAG
‡πÇ‡∏î‡∏¢‡∏ß‡∏±‡∏î metrics ‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÄ‡∏ä‡πà‡∏ô:
- Faithfulness: ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà retrieve ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
- Answer Relevancy: ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
- Context Precision: ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà retrieve ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
- Context Recall: ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà retrieve ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
"""

import os
import json
import sys
import numpy as np
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv
from datetime import datetime

# ‡πÇ‡∏´‡∏•‡∏î environment variables
load_dotenv()

# Import Ragas
try:
    from ragas import evaluate
    from ragas.metrics import (
        faithfulness,
        answer_relevancy,
        context_precision,
        context_recall,
    )
    from datasets import Dataset
except ImportError as e:
    print(f"‚ùå Error importing Ragas: {e}")
    print("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Ragas ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á: pip install ragas datasets")
    sys.exit(1)

# Import RAG system
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from app.retrieval_utils import ask_question_to_rag
from app.birth_date_parser import extract_birth_date_from_message

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ logging
import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def load_test_dataset_from_google_sheets(
    spreadsheet_id: Optional[str] = None,
    worksheet_name: str = "Dataset"
) -> List[Dict[str, Any]]:
    """
    ‡πÇ‡∏´‡∏•‡∏î test dataset ‡∏à‡∏≤‡∏Å Google Sheets
    
    Args:
        spreadsheet_id: ID ‡∏Ç‡∏≠‡∏á Google Spreadsheet (‡∏ñ‡πâ‡∏≤ None ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏à‡∏≤‡∏Å GOOGLE_SHEETS_ID)
        worksheet_name: ‡∏ä‡∏∑‡πà‡∏≠ worksheet ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏≠‡πà‡∏≤‡∏ô
        
    Returns:
        List[Dict]: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á test cases
    """
    try:
        import gspread
        from google.oauth2.service_account import Credentials
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö credentials path
        credentials_path = os.getenv("GOOGLE_SHEETS_CREDENTIALS_PATH")
        if not credentials_path or not os.path.exists(credentials_path):
            logger.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö GOOGLE_SHEETS_CREDENTIALS_PATH")
            return []
        
        # ‡πÇ‡∏´‡∏•‡∏î credentials
        creds = Credentials.from_service_account_file(
            credentials_path,
            scopes=['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']
        )
        client = gspread.authorize(creds)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö spreadsheet_id
        if spreadsheet_id is None:
            spreadsheet_id = os.getenv("GOOGLE_SHEETS_ID")
        
        if not spreadsheet_id:
            logger.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö GOOGLE_SHEETS_ID")
            return []
        
        # ‡πÅ‡∏¢‡∏Å Spreadsheet ID ‡∏à‡∏≤‡∏Å URL (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
        if "/d/" in spreadsheet_id:
            parts = spreadsheet_id.split("/d/")
            if len(parts) > 1:
                spreadsheet_id = parts[1].split("/")[0].split("?")[0].split("#")[0]
        
        logger.info(f"üìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î dataset ‡∏à‡∏≤‡∏Å Google Sheets: {spreadsheet_id}")
        
        # ‡πÄ‡∏õ‡∏¥‡∏î spreadsheet
        spreadsheet = client.open_by_key(spreadsheet_id)
        
        # ‡πÄ‡∏õ‡∏¥‡∏î worksheet
        try:
            worksheet = spreadsheet.worksheet(worksheet_name)
        except gspread.exceptions.WorksheetNotFound:
            logger.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö worksheet: {worksheet_name}")
            return []
        
        # ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        all_values = worksheet.get_all_values()
        
        if len(all_values) < 2:
            logger.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô worksheet")
            return []
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô list of dicts
        headers = all_values[0]
        data = []
        
        for row in all_values[1:]:
            if not row[0]:  # ‡∏Ç‡πâ‡∏≤‡∏°‡πÅ‡∏ñ‡∏ß‡∏ß‡πà‡∏≤‡∏á
                continue
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á dict ‡∏à‡∏≤‡∏Å headers ‡πÅ‡∏•‡∏∞ values
            item = {}
            for i, header in enumerate(headers):
                if i < len(row):
                    item[header] = row[i]
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà evaluate_ragas.py ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
            test_case = {
                "question": item.get("‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°", ""),
                "ground_truth": item.get("‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö (Ground Truth)", ""),
                "contexts": item.get("Contexts", "").split(" | ") if item.get("Contexts") else []
            }
            
            if test_case["question"]:  # ‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
                data.append(test_case)
        
        logger.info(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î test dataset ‡∏à‡∏≤‡∏Å Google Sheets ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(data)} test cases")
        return data
        
    except ImportError:
        logger.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö gspread library")
        return []
    except Exception as e:
        logger.error(f"‚ùå Error loading from Google Sheets: {e}")
        import traceback
        traceback.print_exc()
        return []


def load_test_dataset(file_path: str = "test_dataset.json") -> List[Dict[str, Any]]:
    """
    ‡πÇ‡∏´‡∏•‡∏î test dataset ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå JSON
    
    Args:
        file_path: path ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÑ‡∏ü‡∏•‡πå test dataset
        
    Returns:
        List[Dict]: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á test cases
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        logger.info(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î test dataset ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(data)} test cases")
        return data
    except FileNotFoundError:
        logger.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå {file_path}")
        return []
    except json.JSONDecodeError as e:
        logger.error(f"‚ùå Error parsing JSON: {e}")
        return []


def get_retrieved_contexts(question: str, user_id: str = "evaluation_user") -> List[str]:
    """
    ‡∏î‡∏∂‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà retrieve ‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö RAG ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö ask_question_to_rag
    
    Args:
        question: ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
        user_id: user ID ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô
        
    Returns:
        List[str]: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà retrieve
    """
    try:
        from pymongo import MongoClient
        from sentence_transformers import SentenceTransformer
        import numpy as np
        
        mongo_uri = os.getenv("MONGO_URL")
        if not mongo_uri:
            logger.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö MONGO_URL ‡πÉ‡∏ô environment variables")
            return []
        
        # ‡πÇ‡∏´‡∏•‡∏î embedding model (‡πÉ‡∏ä‡πâ CPU ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÉ‡∏ô retrieval_utils)
        model = SentenceTransformer("minishlab/potion-multilingual-128M", device="cpu")
        query_embedding = model.encode(question)
        
        # ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ MongoDB
        client = MongoClient(mongo_uri, serverSelectionTimeoutMS=5000)
        db = client["astrobot_summary"]
        
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÉ‡∏ô collections ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÉ‡∏ô retrieval_utils)
        collections_to_search = [
            "processed_text_chunks",
            "processed_image_chunks",
            "processed_table_chunks",
        ]
        
        all_contexts = []
        
        for collection_name in collections_to_search:
            try:
                collection = db[collection_name]
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ collection ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                doc_count = collection.count_documents({})
                if doc_count == 0:
                    continue
                
                # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
                docs = list(collection.find({}))
                
                if not docs:
                    continue
                
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì similarity scores (‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö retrieval_utils)
                similarities = []
                for doc in docs:
                    if 'embeddings' not in doc:
                        continue
                    
                    try:
                        doc_embedding = np.array(doc['embeddings'])
                        
                        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ dimensions ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô
                        if len(doc_embedding) != len(query_embedding):
                            continue
                        
                        # Cosine similarity
                        similarity = np.dot(query_embedding, doc_embedding) / (
                            np.linalg.norm(query_embedding) * np.linalg.norm(doc_embedding)
                        )
                        similarities.append((similarity, doc))
                    except Exception:
                        continue
                
                # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏° similarity score ‡πÅ‡∏•‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å top 10 (‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 5 ‡πÄ‡∏õ‡πá‡∏ô 10 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô)
                similarities.sort(key=lambda x: x[0], reverse=True)
                top_docs = similarities[:10]
                
                # ‡πÉ‡∏ä‡πâ threshold ‡∏ó‡∏µ‡πà‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ (0.05-0.08) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô
                threshold = 0.05
                
                # ‡∏î‡∏∂‡∏á summary ‡∏´‡∏£‡∏∑‡∏≠ text ‡∏à‡∏≤‡∏Å top documents ‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô threshold
                for sim, doc in top_docs:
                    if sim > threshold:
                        # ‡πÉ‡∏ä‡πâ text ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏Å‡πà‡∏≠‡∏ô (‡∏¢‡∏≤‡∏ß‡∏Å‡∏ß‡πà‡∏≤ summary) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô
                        context_text = doc.get("text") or doc.get("summary", "")
                        if context_text and context_text.strip():
                            all_contexts.append(context_text.strip())
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Error searching in {collection_name}: {e}")
                continue
        
        client.close()
        
        # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô contexts (‡πÉ‡∏ä‡πâ top 10 ‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å collections)
        return all_contexts[:10] if all_contexts else []
        
    except Exception as e:
        logger.error(f"‚ùå Error retrieving contexts: {e}")
        import traceback
        traceback.print_exc()
        return []


def run_rag_evaluation(test_cases: List[Dict[str, Any]], user_id: str = "evaluation_user") -> List[Dict[str, Any]]:
    """
    ‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô RAG system
    
    Args:
        test_cases: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á test cases
        user_id: user ID ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô
        
    Returns:
        List[Dict]: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô
    """
    results = []
    
    logger.info(f"üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô RAG system ‡∏î‡πâ‡∏ß‡∏¢ {len(test_cases)} test cases...")
    
    for i, test_case in enumerate(test_cases, 1):
        question = test_case["question"]
        ground_truth = test_case.get("ground_truth", "")
        expected_contexts = test_case.get("contexts", [])
        
        logger.info(f"\n{'='*60}")
        logger.info(f"üìù Test Case {i}/{len(test_cases)}")
        logger.info(f"‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {question}")
        logger.info(f"{'='*60}")
        
        try:
            # 1. ‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö RAG
            logger.info("üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö RAG...")
            answer = ask_question_to_rag(question, user_id=user_id)
            logger.info(f"‚úÖ ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß: {len(answer)} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£)")
            
            # 2. ‡∏î‡∏∂‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà retrieve
            logger.info("üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà retrieve...")
            retrieved_contexts = get_retrieved_contexts(question, user_id)
            logger.info(f"‚úÖ ‡∏î‡∏∂‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÑ‡∏î‡πâ {len(retrieved_contexts)} chunks")
            
            # 3. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Ragas
            result = {
                "question": question,
                "answer": answer,
                "contexts": retrieved_contexts if retrieved_contexts else expected_contexts,
                "ground_truth": ground_truth,
            }
            
            results.append(result)
            
            logger.info(f"‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• test case {i} ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏° delay ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á test cases ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î rate limiting (1-2 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)
            import time
            if i < len(test_cases):
                time.sleep(1.5)  # ‡∏£‡∏≠ 1.5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á test cases
            
        except Exception as e:
            logger.error(f"‚ùå Error processing test case {i}: {e}")
            import traceback
            traceback.print_exc()
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏° delay ‡πÅ‡∏°‡πâ‡πÉ‡∏ô‡∏Å‡∏£‡∏ì‡∏µ error ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ API rate limit
            import time
            time.sleep(2)
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏´‡∏¢‡∏∏‡∏î
            results.append({
                "question": question,
                "answer": "",
                "contexts": [],
                "ground_truth": ground_truth,
            })
    
    return results


def evaluate_with_ragas(evaluation_results: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏î‡πâ‡∏ß‡∏¢ Ragas
    
    Args:
        evaluation_results: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô RAG evaluation
        
    Returns:
        Dict: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏à‡∏≤‡∏Å Ragas
    """
    logger.info(f"\n{'='*60}")
    logger.info("üìä ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏î‡πâ‡∏ß‡∏¢ Ragas...")
    logger.info(f"{'='*60}\n")
    
    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Ragas Dataset
    data = {
        "question": [r["question"] for r in evaluation_results],
        "answer": [r["answer"] for r in evaluation_results],
        "contexts": [r["contexts"] for r in evaluation_results],
        "ground_truth": [r["ground_truth"] for r in evaluation_results],
    }
    
    # ‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏ó‡∏µ‡πà metric ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô NaN
    empty_answers = sum(1 for ans in data["answer"] if not str(ans).strip())
    empty_contexts = sum(1 for ctx in data["contexts"] if not ctx)
    if empty_answers or empty_contexts:
        logger.warning(
            f"‚ö†Ô∏è ‡∏û‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏á {empty_answers} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ‡πÅ‡∏•‡∏∞ contexts ‡∏ß‡πà‡∏≤‡∏á {empty_contexts} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ "
            "‡∏≠‡∏≤‡∏à‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ö‡∏≤‡∏á metric ‡πÄ‡∏õ‡πá‡∏ô NaN ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥"
        )

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Dataset
    dataset = Dataset.from_dict(data)
    
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î metrics ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô
    metrics = [
        faithfulness,           # ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        answer_relevancy,      # ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        context_precision,     # ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà retrieve ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        context_recall,        # ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà retrieve ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    ]
    
    # ‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô
    try:
        logger.info("üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô Ragas...")
        result = evaluate(
            dataset=dataset,
            metrics=metrics,
        )
        
        logger.info("‚úÖ ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")
        
        return result
        
    except Exception as e:
        logger.error(f"‚ùå Error during Ragas evaluation: {e}")
        import traceback
        traceback.print_exc()
        return None


def convert_numpy_types(obj):
    """
    ‡πÅ‡∏õ‡∏•‡∏á numpy types ‡πÄ‡∏õ‡πá‡∏ô Python native types ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö JSON serialization
    
    Args:
        obj: object ‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏°‡∏µ numpy types
        
    Returns:
        object ‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô Python native types ‡πÅ‡∏•‡πâ‡∏ß
    """
    if isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, (np.integer, np.floating)):
        return obj.item()
    elif isinstance(obj, np.bool_):
        return bool(obj)
    elif isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, (list, tuple)):
        return [convert_numpy_types(item) for item in obj]
    else:
        return obj


def save_evaluation_report(ragas_result: Any, output_file: str = "ragas_evaluation_report.json"):
    """
    ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô
    
    Args:
        ragas_result: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å Ragas evaluation
        output_file: ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
        
    Returns:
        Dict: ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏•‡πâ‡∏ß
    """
    try:
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô dictionary
        if hasattr(ragas_result, 'to_pandas'):
            df = ragas_result.to_pandas()
            # ‡πÅ‡∏ó‡∏ô‡∏Ñ‡πà‡∏≤ NaN ‡∏î‡πâ‡∏ß‡∏¢ 0 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡πÄ‡∏õ‡πá‡∏ô NaN
            df = df.fillna(0.0)
            
            # ‡πÅ‡∏õ‡∏•‡∏á DataFrame ‡πÄ‡∏õ‡πá‡∏ô dictionary ‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á numpy types
            detailed_results = df.to_dict("records")
            detailed_results = convert_numpy_types(detailed_results)
            
            report = {
                "timestamp": datetime.now().isoformat(),
                "summary": {
                    "faithfulness": float(df["faithfulness"].mean()) if "faithfulness" in df.columns else None,
                    "answer_relevancy": float(df["answer_relevancy"].mean()) if "answer_relevancy" in df.columns else None,
                    "context_precision": float(df["context_precision"].mean()) if "context_precision" in df.columns else None,
                    "context_recall": float(df["context_recall"].mean()) if "context_recall" in df.columns else None,
                },
                "detailed_results": detailed_results,
            }
        else:
            report = {
                "timestamp": datetime.now().isoformat(),
                "result": str(ragas_result),
            }
        
        # ‡πÅ‡∏õ‡∏•‡∏á numpy types ‡πÉ‡∏ô report ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        report = convert_numpy_types(report)
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        logger.info(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏•‡∏á {output_file}")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•
        if "summary" in report:
            logger.info("\n" + "="*60)
            logger.info("üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô")
            logger.info("="*60)
            for metric, score in report["summary"].items():
                if score is not None:
                    logger.info(f"  {metric}: {score:.4f}")
            logger.info("="*60)
        
        return report
        
    except Exception as e:
        logger.error(f"‚ùå Error saving evaluation report: {e}")
        import traceback
        traceback.print_exc()
        return None


def connect_to_google_sheets(credentials_path: Optional[str] = None) -> Optional[Any]:
    """
    ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Google Sheets API
    
    Args:
        credentials_path: path ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÑ‡∏ü‡∏•‡πå service account credentials JSON
                         ‡∏ñ‡πâ‡∏≤ None ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏à‡∏≤‡∏Å environment variable GOOGLE_SHEETS_CREDENTIALS_PATH
                         ‡∏´‡∏£‡∏∑‡∏≠ GOOGLE_SHEETS_CREDENTIALS (JSON string)
    
    Returns:
        gspread.Client ‡∏´‡∏£‡∏∑‡∏≠ None ‡∏ñ‡πâ‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
    """
    try:
        import gspread
        from google.oauth2.service_account import Credentials
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö credentials path
        if credentials_path is None:
            credentials_path = os.getenv("GOOGLE_SHEETS_CREDENTIALS_PATH")
        
        # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ credentials path
        if credentials_path and os.path.exists(credentials_path):
            logger.info(f"üìÅ ‡πÉ‡∏ä‡πâ credentials ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå: {credentials_path}")
            creds = Credentials.from_service_account_file(
                credentials_path,
                scopes=['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']
            )
            client = gspread.authorize(creds)
            logger.info("‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Google Sheets ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (‡πÉ‡∏ä‡πâ service account file)")
            return client
        
        # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ credentials ‡πÄ‡∏õ‡πá‡∏ô JSON string ‡πÉ‡∏ô environment variable
        credentials_json = os.getenv("GOOGLE_SHEETS_CREDENTIALS")
        if credentials_json:
            logger.info("üìÅ ‡πÉ‡∏ä‡πâ credentials ‡∏à‡∏≤‡∏Å environment variable")
            import json as json_lib
            creds_info = json_lib.loads(credentials_json)
            creds = Credentials.from_service_account_info(
                creds_info,
                scopes=['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']
            )
            client = gspread.authorize(creds)
            logger.info("‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Google Sheets ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (‡πÉ‡∏ä‡πâ service account JSON)")
            return client
        
        logger.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö Google Sheets credentials")
        logger.info("üí° ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ GOOGLE_SHEETS_CREDENTIALS_PATH ‡∏´‡∏£‡∏∑‡∏≠ GOOGLE_SHEETS_CREDENTIALS ‡πÉ‡∏ô .env")
        return None
        
    except ImportError:
        logger.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö gspread library. ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏î‡πâ‡∏ß‡∏¢: pip install gspread google-auth")
        return None
    except Exception as e:
        logger.error(f"‚ùå Error connecting to Google Sheets: {e}")
        import traceback
        traceback.print_exc()
        return None


def send_to_google_sheets(
    ragas_result: Any,
    spreadsheet_id: Optional[str] = None,
    worksheet_name: str = "RAGAS Evaluation",
    evaluation_results: Optional[List[Dict[str, Any]]] = None
) -> bool:
    """
    ‡∏™‡πà‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô RAGAS ‡πÑ‡∏õ‡∏¢‡∏±‡∏á Google Sheets
    
    Args:
        ragas_result: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å Ragas evaluation
        spreadsheet_id: ID ‡∏Ç‡∏≠‡∏á Google Spreadsheet (‡∏ñ‡πâ‡∏≤ None ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏à‡∏≤‡∏Å GOOGLE_SHEETS_ID)
        worksheet_name: ‡∏ä‡∏∑‡πà‡∏≠ worksheet ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
        evaluation_results: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô RAG (optional)
    
    Returns:
        bool: True ‡∏ñ‡πâ‡∏≤‡∏™‡πà‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à, False ‡∏ñ‡πâ‡∏≤‡∏™‡πà‡∏á‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
    """
    try:
        import gspread
        
        # ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Google Sheets
        client = connect_to_google_sheets()
        if client is None:
            return False
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö spreadsheet_id
        if spreadsheet_id is None:
            spreadsheet_id = os.getenv("GOOGLE_SHEETS_ID")
        
        if not spreadsheet_id:
            logger.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö GOOGLE_SHEETS_ID ‡πÉ‡∏ô environment variables")
            logger.info("üí° ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ GOOGLE_SHEETS_ID ‡πÉ‡∏ô .env (‡πÄ‡∏ä‡πà‡∏ô: https://docs.google.com/spreadsheets/d/SPREADSHEET_ID/edit)")
            return False
        
        logger.info(f"üìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡∏¢‡∏±‡∏á Google Sheets: {spreadsheet_id}")
        
        # ‡πÄ‡∏õ‡∏¥‡∏î spreadsheet
        spreadsheet = client.open_by_key(spreadsheet_id)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ worksheet ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà
        try:
            worksheet = spreadsheet.worksheet(worksheet_name)
            logger.info(f"‚úÖ ‡∏û‡∏ö worksheet: {worksheet_name}")
        except gspread.exceptions.WorksheetNotFound:
            worksheet = spreadsheet.add_worksheet(title=worksheet_name, rows=1000, cols=20)
            logger.info(f"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á worksheet ‡πÉ‡∏´‡∏°‡πà: {worksheet_name}")
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô DataFrame
        if hasattr(ragas_result, 'to_pandas'):
            df = ragas_result.to_pandas()
            df = df.fillna(0.0)
        else:
            logger.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏õ‡∏•‡∏á ragas_result ‡πÄ‡∏õ‡πá‡∏ô DataFrame ‡πÑ‡∏î‡πâ")
            return False
        
        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
        # Header row
        headers = [
            "Timestamp",
            "Question",
            "Answer",
            "Ground Truth",
            "Faithfulness",
            "Answer Relevancy",
            "Context Precision",
            "Context Recall",
        ]
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å evaluation_results ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
        if evaluation_results:
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á mapping ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á question ‡∏Å‡∏±‡∏ö evaluation result
            eval_map = {r["question"]: r for r in evaluation_results}
            
            # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• rows
            rows = []
            for idx, row in df.iterrows():
                question = row.get("question", "")
                eval_result = eval_map.get(question, {})
                
                row_data = [
                    datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    question,
                    eval_result.get("answer", "")[:500],  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß
                    row.get("ground_truth", "")[:500],
                    round(float(row.get("faithfulness", 0.0)), 4),
                    round(float(row.get("answer_relevancy", 0.0)), 4),
                    round(float(row.get("context_precision", 0.0)), 4),
                    round(float(row.get("context_recall", 0.0)), 4),
                ]
                rows.append(row_data)
        else:
            # ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å DataFrame ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
            rows = []
            for idx, row in df.iterrows():
                row_data = [
                    datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    row.get("question", ""),
                    "",  # answer (‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô ragas_result)
                    row.get("ground_truth", "")[:500],
                    round(float(row.get("faithfulness", 0.0)), 4),
                    round(float(row.get("answer_relevancy", 0.0)), 4),
                    round(float(row.get("context_precision", 0.0)), 4),
                    round(float(row.get("context_recall", 0.0)), 4),
                ]
                rows.append(row_data)
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° summary row
        summary_row = [
            datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "=== SUMMARY ===",
            "",
            "",
            round(float(df["faithfulness"].mean()), 4) if "faithfulness" in df.columns else 0.0,
            round(float(df["answer_relevancy"].mean()), 4) if "answer_relevancy" in df.columns else 0.0,
            round(float(df["context_precision"].mean()), 4) if "context_precision" in df.columns else 0.0,
            round(float(df["context_recall"].mean()), 4) if "context_recall" in df.columns else 0.0,
        ]
        
        # ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤ (‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£) ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà
        clear_existing = os.getenv("GOOGLE_SHEETS_CLEAR_EXISTING", "false").lower() == "true"
        
        if clear_existing:
            worksheet.clear()
            logger.info("üóëÔ∏è ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡πÉ‡∏ô worksheet")
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å headers
        worksheet.update(values=[headers], range_name='A1:H1')
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        if rows:
            worksheet.update(values=rows, range_name=f'A2:H{len(rows)+1}')
            logger.info(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {len(rows)} rows")
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å summary
        summary_start_row = len(rows) + 3
        worksheet.update(values=[summary_row], range_name=f'A{summary_start_row}:H{summary_start_row}')
        worksheet.update(values=[["=== SUMMARY ==="]], range_name=f'A{summary_start_row}')
        logger.info(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å summary ‡∏ó‡∏µ‡πà row {summary_start_row}")
        
        # Format header row
        worksheet.format('A1:H1', {
            'backgroundColor': {'red': 0.2, 'green': 0.4, 'blue': 0.8},
            'textFormat': {'bold': True, 'foregroundColor': {'red': 1.0, 'green': 1.0, 'blue': 1.0}}
        })
        
        logger.info(f"‚úÖ ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡∏¢‡∏±‡∏á Google Sheets ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
        logger.info(f"üìä Spreadsheet: {spreadsheet.url}")
        return True
        
    except ImportError:
        logger.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö gspread library. ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏î‡πâ‡∏ß‡∏¢: pip install gspread google-auth")
        return False
    except Exception as e:
        logger.error(f"‚ùå Error sending to Google Sheets: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô"""
    logger.info("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏∞‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô Ragas ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ä‡∏ó‡∏ö‡∏≠‡∏ó‡πÇ‡∏´‡∏£‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå")
    logger.info("="*60)
    
    # 1. ‡πÇ‡∏´‡∏•‡∏î test dataset (‡∏•‡∏≠‡∏á‡∏à‡∏≤‡∏Å Google Sheets ‡∏Å‡πà‡∏≠‡∏ô ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ä‡πâ JSON)
    google_sheets_enabled = os.getenv("GOOGLE_SHEETS_ENABLED", "false").lower() == "true"
    test_cases = []
    
    if google_sheets_enabled:
        logger.info("üìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î dataset ‡∏à‡∏≤‡∏Å Google Sheets...")
        test_cases = load_test_dataset_from_google_sheets(worksheet_name="Dataset")
        if test_cases:
            logger.info(f"‚úÖ ‡πÉ‡∏ä‡πâ dataset ‡∏à‡∏≤‡∏Å Google Sheets: {len(test_cases)} test cases")
    
    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Google Sheets ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å JSON
    if not test_cases:
        dataset_file = "dataset_from_mongo.json"
        if not os.path.exists(dataset_file):
            dataset_file = "test_dataset.json"
            logger.info(f"üìÅ ‡πÉ‡∏ä‡πâ dataset ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå: {dataset_file}")
        else:
            logger.info(f"üìÅ ‡πÉ‡∏ä‡πâ dataset ‡∏à‡∏≤‡∏Å MongoDB: {dataset_file}")
        
        test_cases = load_test_dataset(dataset_file)
        if not test_cases:
            logger.error("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ test cases ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô")
            logger.info("üí° ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á: python3 generate_ragas_dataset_from_mongo.py ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á dataset ‡∏à‡∏≤‡∏Å MongoDB")
            return
    
    # 2. ‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô RAG system
    evaluation_results = run_rag_evaluation(test_cases, user_id="ragas_evaluation")
    
    if not evaluation_results:
        logger.error("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô")
        return
    
    # 3. ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏î‡πâ‡∏ß‡∏¢ Ragas
    ragas_result = evaluate_with_ragas(evaluation_results)
    
    if ragas_result is None:
        logger.error("‚ùå ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô Ragas ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß")
        return
    
    # 4. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô
    report = save_evaluation_report(ragas_result, "ragas_evaluation_report.json")
    
    # 5. ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡∏¢‡∏±‡∏á Google Sheets (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤)
    google_sheets_enabled = os.getenv("GOOGLE_SHEETS_ENABLED", "false").lower() == "true"
    if google_sheets_enabled:
        logger.info("\n" + "="*60)
        logger.info("üìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡∏¢‡∏±‡∏á Google Sheets...")
        logger.info("="*60)
        success = send_to_google_sheets(
            ragas_result=ragas_result,
            evaluation_results=evaluation_results
        )
        if success:
            logger.info("‚úÖ ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡∏¢‡∏±‡∏á Google Sheets ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
        else:
            logger.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡∏¢‡∏±‡∏á Google Sheets ‡πÑ‡∏î‡πâ (‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö credentials)")
    else:
        logger.info("\nüí° ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡∏¢‡∏±‡∏á Google Sheets? ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ GOOGLE_SHEETS_ENABLED=true ‡πÉ‡∏ô .env")
    
    logger.info("\n‚úÖ ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")


if __name__ == "__main__":
    main()

