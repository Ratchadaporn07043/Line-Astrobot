import os
import json
import random
import pandas as pd
from pymongo import MongoClient
from dotenv import load_dotenv
from openai import OpenAI
from tqdm import tqdm

# Load environment variables
load_dotenv()

MONGO_URL = os.getenv("MONGO_URL")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
DB_NAME = "astrobot_original"  # Correct DB for content chunks
# Based on multimodel_rag.py
COLLECTIONS = ["original_text_chunks", "original_image_chunks", "original_table_chunks"]

KEYWORDS = ["‡∏ß‡∏±‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏õ‡∏µ‡πÄ‡∏Å‡∏¥‡∏î", "‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏Å‡∏¥‡∏î", "‡∏Å‡∏≤‡∏£‡∏á‡∏≤‡∏ô", "‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô", "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏±‡∏Å", "‡∏™‡∏µ‡∏°‡∏á‡∏Ñ‡∏•"]
TARGET_COUNT = 10

def get_mongo_client():
    try:
        client = MongoClient(MONGO_URL)
        # Verify connection
        client.admin.command('ping')
        print(f"‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ MongoDB ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {MONGO_URL.split('@')[-1]}")  # Hide credentials
        return client
    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ MongoDB ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e}")
        return None

def fetch_candidate_chunks(client, db_name, collections, keywords, limit_per_keyword=50):
    db = client[db_name]
    candidates = []
    
    print(f"\nüîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å MongoDB Database: '{db_name}'...")
    
    for collection_name in collections:
        if collection_name not in db.list_collection_names():
            print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö Collection: {collection_name} - ‡∏Ç‡πâ‡∏≤‡∏°")
            continue
            
        collection = db[collection_name]
        doc_count = collection.count_documents({})
        print(f"   üìÇ Collection '{collection_name}' ‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {doc_count} ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£")
        
        for keyword in keywords:
            # Simple text search regex
            query = {"text": {"$regex": keyword, "$options": "i"}}
            cursor = collection.find(query).limit(limit_per_keyword)
            found_docs = list(cursor)
            
            if found_docs:
                print(f"      - Keyword '{keyword}': ‡∏û‡∏ö {len(found_docs)} ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£")
                for doc in found_docs:
                    # Avoid duplicates if traversing multiple keywords
                    if not any(c['_id'] == doc['_id'] for c in candidates):
                        candidates.append({
                            "_id": str(doc['_id']),
                            "text": doc.get('text', ''),
                            "source": doc.get('source', 'Unknown'),
                            "page": doc.get('page', 'N/A'),
                            "collection": collection_name,
                            "matched_keyword": keyword
                        })
    
    print(f"‚úÖ ‡∏£‡∏ß‡∏°‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(candidates)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    
    # Verification: Print the first retrieved document to prove it comes from MongoDB
    if candidates:
        sample = candidates[0]
        print("\nüîé [Verification] ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤‡∏à‡∏≤‡∏Å MongoDB:")
        print(f"   üÜî ID: {sample['_id']}")
        print(f"   üìÇ Collection: {sample['collection']}")
        print(f"   üìÑ Source: {sample['source']}")
        print(f"   üìù Text (Snippet): {sample['text'][:200]}...")
        print("--------------------------------------------------\n")
        
    return candidates

def generate_qa_pair(client_openai, context):
    prompt = f"""
    ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏≠‡∏¢‡∏π‡πà‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ
    ---------------------
    {context}
    ---------------------
    ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÉ‡∏´‡πâ (‡πÅ‡∏•‡∏∞‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏≠‡∏∑‡πà‡∏ô‡∏ô‡∏≠‡∏Å‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏à‡∏≤‡∏Å‡∏ö‡∏£‡∏¥‡∏ö‡∏ó)
    ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á "‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°" ‡πÅ‡∏•‡∏∞ "‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö" ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô 1 ‡∏Ñ‡∏π‡πà
    
    ‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (Critical Requirement):
    1. ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° **‡∏ï‡πâ‡∏≠‡∏á** ‡∏£‡∏∞‡∏ö‡∏∏ "‡∏ß‡∏±‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏õ‡∏µ‡πÄ‡∏Å‡∏¥‡∏î" ‡πÅ‡∏•‡∏∞ "‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏Å‡∏¥‡∏î" ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á‡∏•‡∏á‡πÑ‡∏õ‡πÉ‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö **DD/MM/YYYY (‡∏õ‡∏µ ‡∏Ñ.‡∏®. ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô)** ‡πÄ‡∏ä‡πà‡∏ô "07/09/2003", "15/04/1990", "10/12/1985"
    2. ‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ß‡∏±‡∏ô‡πÄ‡∏Å‡∏¥‡∏î‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏£‡∏≤‡∏®‡∏µ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏≤‡∏Å‡∏è‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó (‡πÄ‡∏ä‡πà‡∏ô ‡∏ñ‡πâ‡∏≤‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏û‡∏π‡∏î‡∏ñ‡∏∂‡∏á‡∏£‡∏≤‡∏®‡∏µ‡πÄ‡∏°‡∏© ‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏∏‡πà‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏£‡∏≤‡∏®‡∏µ‡πÄ‡∏°‡∏©) ‡∏ñ‡πâ‡∏≤‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏≤‡∏®‡∏µ ‡πÉ‡∏´‡πâ‡∏™‡∏∏‡πà‡∏°‡∏ß‡∏±‡∏ô‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏≠‡∏≤
    3. ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó (‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏á‡∏≤‡∏ô, ‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô, ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏±‡∏Å) ‡πÇ‡∏î‡∏¢‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏Å‡∏±‡∏ö‡∏ß‡∏±‡∏ô‡πÄ‡∏Å‡∏¥‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏Å‡∏¥‡∏î‡∏ô‡∏±‡πâ‡∏ô
    4. ‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏Å‡∏¥‡∏î‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
    5. ‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏Å‡∏¥‡∏î‡∏™‡∏•‡∏±‡∏ö‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏Å‡∏¥‡∏î
    6. **‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢** ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÅ‡∏•‡∏∞‡∏ó‡∏±‡∏ö (/) ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    
    ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏†‡∏≤‡∏©‡∏≤:
    - ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
    - ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ‡πÇ‡∏î‡∏¢‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ß‡∏±‡∏ô‡πÄ‡∏Å‡∏¥‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏Å‡∏¥‡∏î‡∏ô‡∏±‡πâ‡∏ô‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
    
    Format the output as JSON:
    {{
        "question": "‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡∏±‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏Å‡∏¥‡∏î",
        "answer": "‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢"
    }}
    """
    
    try:
        response = client_openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are a helpful assistant that generates Q&A pairs from text."},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"}
        )
        return json.loads(response.choices[0].message.content)
    except Exception as e:
        print(f"Error generating Q&A: {e}")
        return None

def main():
    if not MONGO_URL:
        print("‚ùå Error: MONGO_URL not found in environment variables.")
        return
    if not OPENAI_API_KEY:
        print("‚ùå Error: OPENAI_API_KEY not found in environment variables.")
        return

    mongo_client = get_mongo_client()
    if not mongo_client:
        return

    # 1. Fetch Data from MongoDB
    print("\n--- ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ---")
    candidates = fetch_candidate_chunks(mongo_client, DB_NAME, COLLECTIONS, KEYWORDS)
    
    if len(candidates) < TARGET_COUNT:
        print(f"‚ö†Ô∏è ‡∏û‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏û‡∏µ‡∏¢‡∏á {len(candidates)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ‡∏ã‡∏∂‡πà‡∏á‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ {TARGET_COUNT} ‡∏Ç‡πâ‡∏≠")
        print("   ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏ã‡πâ‡∏≥‡∏´‡∏≤‡∏Å‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô)")
    
    # Select samples (ensure diversity if possible, or just take random allowed)
    # If we have enough, sample w/o replacement. If not, we might need to reuse or just clamp.
    if len(candidates) >= TARGET_COUNT:
        selected_chunks = random.sample(candidates, TARGET_COUNT)
    else:
        selected_chunks = candidates # Take all
    
    print(f"\n--- ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Q&A ‡∏î‡πâ‡∏ß‡∏¢ LLM ({len(selected_chunks)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£) ---")
    openai_client = OpenAI(api_key=OPENAI_API_KEY)
    
    dataset = []
    
    for i, chunk in enumerate(tqdm(selected_chunks, desc="Generating")):
        try:
            qa = generate_qa_pair(openai_client, chunk['text'])
            if qa:
                dataset.append({
                    "question": qa['question'],
                    "ground_truth": qa['answer'], # Ragas expects 'ground_truth' or 'ground_truths' usually, but for simple viewing 'answer' is fine. We will use 'answer' for CSV
                    "answer": qa['answer'],      # Keeping 'answer' for clear CSV reading
                    "context": chunk['text'],    # Ragas expects 'contexts' as list of strings
                    "source_page": chunk['page'],
                    "collection": chunk['collection'],
                    "keyword": chunk['matched_keyword']
                })
        except Exception as e:
            print(f"Skipping chunk {i}: {e}")

    # Output to files
    df = pd.DataFrame(dataset)
    
    # Create final JSON structure for Ragas (if we were using the HF dataset loader directly, but simple JSON/CSV is fine for our custom evaluation script)
    # We will save as simple records
    
    print("\n--- ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ---")
    print(f"üìä ‡πÑ‡∏î‡πâ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏ô‡∏ß‡∏ô: {len(df)} ‡∏Ç‡πâ‡∏≠")
    
    csv_path = "generated_dataset.csv"
    json_path = "generated_dataset.json"
    
    df.to_csv(csv_path, index=False, encoding='utf-8-sig') # utf-8-sig for Excel Thai support
    df.to_csv(csv_path, index=False, encoding='utf-8-sig') # utf-8-sig for Excel Thai support
    
    # Use json.dump for cleaner formatting (no escaped /)
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(dataset, f, ensure_ascii=False, indent=2)
    
    print(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå CSV ‡∏ó‡∏µ‡πà: {os.path.abspath(csv_path)}")
    print(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå JSON ‡∏ó‡∏µ‡πà: {os.path.abspath(json_path)}")

if __name__ == "__main__":
    main()
